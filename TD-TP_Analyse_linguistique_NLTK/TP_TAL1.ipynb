{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TP1 de TAL (Polytech Paris-Saclay 2024 - Traitement Automatique des Langues)\n",
        "\n"
      ],
      "metadata": {
        "id": "fEZUrYR_7GMF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SzD3ReK5bHl"
      },
      "outputs": [],
      "source": [
        "pip install --user -U nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --user -U numpy"
      ],
      "metadata": {
        "id": "UyFclxOk6_qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test de NLTK (pour voir si tout fonctionne)"
      ],
      "metadata": {
        "id": "c1HFtEc07UWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "text = \"It’s works!\"\n",
        "print(word_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqejiIQm7FNX",
        "outputId": "47356593-a430-42f8-d567-5f23be56ff1c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', '’', 's', 'works', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Evaluation de l’analyse morpho-syntaxique de la plateforme NLTK"
      ],
      "metadata": {
        "id": "FyaqYa078M5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "# Assurez-vous d'avoir téléchargé le corpus nécessaire pour pos_tag\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6YxG4178Wnc",
        "outputId": "54cade3d-ca55-4555-dd2f-429bf1dedcb6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le contenu du fichier\n",
        "with open('wsj_0010_sample.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Tokenisation du texte\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Analyse morphosyntaxique avec pos_tag\n",
        "tagged_tokens = pos_tag(tokens)\n",
        "\n",
        "# Création du texte avec les tags\n",
        "tagged_text = ' '.join([f'{word}/{tag}' for word, tag in tagged_tokens])\n",
        "\n",
        "# Écriture dans le fichier de sortie\n",
        "output_filename = 'wsj_0010_sample.txt.pos.nltk'\n",
        "with open(output_filename, 'w') as output_file:\n",
        "    output_file.write(tagged_text)\n",
        "\n",
        "print(f\"Résultats écrits dans {output_filename} - Fichier généré\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca2LUH1l8Mas",
        "outputId": "7b2967c4-b2c8-4bd7-921e-0fafbd9345fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résultats écrits dans wsj_0010_sample.txt.pos.nltk - Fichier généré\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Utilisation de la plateforme NLTK pour l’analyse syntaxique"
      ],
      "metadata": {
        "id": "7YVhQMJ38-VL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OwWT-OFf9ASl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}